# ü¶ô LaMa Anime/Manga Inpainting - RunPod Serverless CPU

RunPod Serverless CPU –≤–µ—Ä—Å–∏—è –¥–ª—è –∏–Ω–ø–µ–π–Ω—Ç–∏–Ω–≥–∞ –º–∞–Ω–≥–∏ –∏ –∞–Ω–∏–º–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ [LaMa](https://github.com/advimman/lama)

## üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- ‚úÖ **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å**: `lama_large_512px.ckpt` –æ–±—É—á–µ–Ω–∞ –Ω–∞ –∞–Ω–∏–º–µ/–º–∞–Ω–≥–µ
- ‚úÖ **CPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ GPU, —ç–∫–æ–Ω–æ–º–∏—á–Ω–æ
- ‚úÖ **RunPod Serverless**: –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ
- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Å–∞–π–∑**: –¥–æ 1024px –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
- ‚úÖ **Base64 I/O**: —É–¥–æ–±–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å API

## üì¶ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è RunPod

```
manga-inpaint/
‚îú‚îÄ‚îÄ rp_handler_cpu.py           # CPU –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è RunPod
‚îú‚îÄ‚îÄ runpod_cpu.yaml            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è RunPod CPU
‚îú‚îÄ‚îÄ Dockerfile.runpod_cpu      # Docker –æ–±—Ä–∞–∑ –¥–ª—è RunPod
‚îú‚îÄ‚îÄ local-model/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ best_genpref.ckpt # –ú–æ–¥–µ–ª—å (195MB)
‚îî‚îÄ‚îÄ saicinpainting/           # –ö–æ–¥ LaMa
```

## üöÄ –î–µ–ø–ª–æ–π –Ω–∞ RunPod

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞

```bash
cd /Users/alizhan_nh/Desktop/ai/manga-inpaint

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –º–æ–¥–µ–ª—å –µ—Å—Ç—å
ls -lh lama_large_512px.ckpt

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤ local-model –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
cp lama_large_512px.ckpt local-model/models/best_genpref.ckpt
```

### 2. –î–µ–ø–ª–æ–π —á–µ—Ä–µ–∑ RunPod CLI

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å RunPod CLI (–µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
pip install runpod

# –í–æ–π—Ç–∏ –≤ –∞–∫–∫–∞—É–Ω—Ç
runpod login

# –î–µ–ø–ª–æ–π CPU –≤–µ—Ä—Å–∏–∏
runpod deploy --template runpod_cpu.yaml
```

### 3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –¥–µ–ø–ª–æ–π —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

1. –ó–∞–π—Ç–∏ –Ω–∞ [RunPod Console](https://console.runpod.io)
2. –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π Serverless Endpoint
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ `runpod_cpu.yaml`:
   - **GPU**: Disabled (CPU only)
   - **Template**: Custom
   - **Dockerfile**: `Dockerfile.runpod_cpu`

## üì° API –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞

```json
{
  "input": {
    "image": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD...",
    "mask": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
  }
}
```

### –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞

```json
{
  "status": "ok",
  "image_base64": "/9j/4AAQSkZJRgABAQEAYABgAAD...",
  "metadata": {
    "input_size": [720, 1098],
    "output_size": [512, 328],
    "device": "cpu",
    "model": "lama_large_512px_anime_manga"
  }
}
```

### –ü—Ä–∏–º–µ—Ä —Å Python

```python
import requests
import base64
from PIL import Image
import io

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
def image_to_base64(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()

# –í–∞—à RunPod endpoint
ENDPOINT_URL = "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync"

# –ó–∞–ø—Ä–æ—Å
payload = {
    "input": {
        "image": image_to_base64("input.png"),
        "mask": image_to_base64("mask.png")
    }
}

response = requests.post(ENDPOINT_URL, json=payload, headers={
    "Authorization": "Bearer YOUR_API_KEY"
})

result = response.json()

if result["status"] == "ok":
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    img_data = base64.b64decode(result["image_base64"])
    with open("output.png", "wb") as f:
        f.write(img_data)
    print("‚úÖ Inpainting completed!")
else:
    print(f"‚ùå Error: {result['message']}")
```

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```yaml
env:
  - key: MODEL_DIR
    value: /app/local-model
  - key: MODEL_CKPT
    value: best_genpref.ckpt
  - key: DEVICE
    value: cpu
  - key: MAX_SIZE
    value: "1024"  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
  - key: MODEL_URL
    value: "https://huggingface.co/dreMaz/AnimeMangaInpainting/resolve/main/lama_large_512px.ckpt?download=true"
```

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

- **MAX_SIZE**: —É–º–µ–Ω—å—à–∏—Ç–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (512, 768, 1024)
- **Timeout**: —É–≤–µ–ª–∏—á—å—Ç–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (30-60 —Å–µ–∫)
- **Memory**: RunPod –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–¥–µ–ª—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è CPU

## üìä –û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

**CPU (RunPod Serverless)**
- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: ~10-15 —Å–µ–∫ (cold start)
- Inference 512x512: ~15-30 —Å–µ–∫
- Inference 1024x1024: ~30-60 —Å–µ–∫
- Warm inference: ~10-20 —Å–µ–∫ (–ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏)

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –û—à–∏–±–∫–∞: "Out of memory"
```yaml
# –£–º–µ–Ω—å—à–∏—Ç–µ MAX_SIZE –≤ runpod_cpu.yaml
- key: MAX_SIZE
  value: "512"
```

### –û—à–∏–±–∫–∞: "Model not found"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞
ls -lh local-model/models/best_genpref.ckpt
```

### –û—à–∏–±–∫–∞: "Timeout"
- –£–≤–µ–ª–∏—á—å—Ç–µ timeout –≤ RunPod –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

## üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å

RunPod Serverless CPU:
- **Cold start**: ~$0.01-0.02 –∑–∞ –∑–∞–ø—Ä–æ—Å
- **Warm inference**: ~$0.005-0.01 –∑–∞ –∑–∞–ø—Ä–æ—Å
- **–≠–∫–æ–Ω–æ–º–∏—á–Ω–æ** –¥–ª—è –Ω–µ—á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [LaMa Original](https://github.com/advimman/lama) - –±–∞–∑–æ–≤—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
- [RunPod Serverless](https://docs.runpod.io/serverless/) - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è RunPod
- [AnimeMangaInpainting Model](https://huggingface.co/dreMaz/AnimeMangaInpainting) - –º–æ–¥–µ–ª—å

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

Apache-2.0 (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º LaMa)

---

**–í–µ—Ä—Å–∏—è**: CPU Serverless  
**–ú–æ–¥–µ–ª—å**: lama_large_512px.ckpt  
**–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞**: RunPod Serverless  
**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –ê–Ω–∏–º–µ/–º–∞–Ω–≥–∞
